{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c39d6a9-b94e-4dad-9d01-531befbd6339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e3dd45-fd27-4a3e-b155-fb47f0037f16",
   "metadata": {},
   "source": [
    "## Load Stored Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff1df313-896f-4d86-ac7b-2927fd69a27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.sets import load_sets\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_sets(path='../data/processed/beer_type/'\n",
    "                                                          )\n",
    "                                                           \n",
    "from src.models.pytorch import PytorchDataset\n",
    "\n",
    "train_dataset = PytorchDataset(X=X_train, y=y_train)\n",
    "val_dataset = PytorchDataset(X=X_val, y=y_val)\n",
    "test_dataset = PytorchDataset(X=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c624d0e-c55d-42e8-b64b-71264d95472d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.08775722, -3.20467771, -1.36609615, -1.09012252, -0.40009933,\n",
       "        -1.09466486],\n",
       "       [-0.05561711, -1.05449924,  0.25703654, -0.35721912, -0.40009933,\n",
       "         0.62759846],\n",
       "       [ 1.11334619, -1.05449924, -0.55452981,  0.37568428, -0.40009933,\n",
       "         0.06786288],\n",
       "       ...,\n",
       "       [ 1.34054826,  0.37895308,  0.25703654,  0.37568428,  0.96607804,\n",
       "         1.14427745],\n",
       "       [ 0.56586437,  0.37895308, -0.55452981, -1.09012252,  0.28298936,\n",
       "        -0.01825029],\n",
       "       [ 0.40630261,  0.37895308,  1.06860288,  0.37568428, -0.40009933,\n",
       "         0.41231554]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff56144-1c50-4d41-9d7b-a899d0354a42",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f15dd0-34bd-4c41-94e6-31a5db5f975c",
   "metadata": {},
   "source": [
    "### Architecture 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8077194-2b4d-47ce-8ab3-1361e8f637ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PytorchMultiClass(\n",
       "  (layer_1): Linear(in_features=6, out_features=50, bias=True)\n",
       "  (layer_out): Linear(in_features=50, out_features=104, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate PytorchMultiClass with the correct number of input feature \n",
    "# and save it into a variable called model\n",
    "\n",
    "from src.models.pytorch import PytorchMultiClass\n",
    "model = PytorchMultiClass(X_train.shape[1])\n",
    "\n",
    "\n",
    "# Set model to use the device available\n",
    "from src.models.pytorch import get_device\n",
    "\n",
    "device = get_device()\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "146e8bfb-b89b-4fc4-bdff-569075a5b44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PytorchMultiClass(\n",
      "  (layer_1): Linear(in_features=6, out_features=50, bias=True)\n",
      "  (layer_out): Linear(in_features=50, out_features=104, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Print the architecture of model\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939c4fd2-dae4-40cc-a470-8f5faea7fc97",
   "metadata": {},
   "source": [
    "#### Train\n",
    "Neural Network Multi-Class Classification with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35d462d1-029f-46b0-a664-aafe53d39a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate a nn.CrossEntropyLoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "N_EPOCHS = 2\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6a6b71-3dd6-4e74-97c8-67143e0584ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "N_EPOCHS = 5\n",
    "BATCH_SIZE = 500000\n",
    "\n",
    "\n",
    "from src.models.pytorch import train_classification, test_classification\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train_classification(train_dataset,\n",
    "                                                 model=model,\n",
    "                                                 criterion=criterion,\n",
    "                                                 optimizer=optimizer,\n",
    "                                                 batch_size=BATCH_SIZE,\n",
    "                                                 device=device\n",
    "                                                )\n",
    "    \n",
    "    valid_loss, valid_acc = test_classification(val_dataset,\n",
    "                                                model=model,\n",
    "                                                criterion=criterion,\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                device=device\n",
    "                                               )\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\t|\\tLoss: {train_loss:.4f}\\t|\\tAcc: {train_acc * 100:.3f}%')\n",
    "    print(f'\\t(valid)\\t|\\tLoss: {valid_loss:.4f}\\t|\\tAcc: {valid_acc * 100:.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dbdbce-46ac-4d45-9f69-788e977ca188",
   "metadata": {},
   "source": [
    "## Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da14beab-351c-4ce6-a2d7-622d47def42d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PytorchMultiClass(\n",
       "  (layer_1): Linear(in_features=6, out_features=50, bias=True)\n",
       "  (layer_out): Linear(in_features=50, out_features=104, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate PytorchMultiClass with the correct number of input feature \n",
    "# and save it into a variable called model\n",
    "\n",
    "from src.models.pytorch import PytorchMultiClass\n",
    "model = PytorchMultiClass(X_train.shape[1])\n",
    "\n",
    "\n",
    "# Set model to use the device available\n",
    "from src.models.pytorch import get_device\n",
    "\n",
    "device = get_device()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b1efa5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.691%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n",
      "Epoch: 1\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n",
      "Epoch: 2\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n",
      "Epoch: 3\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n",
      "Epoch: 4\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "N_EPOCHS = 5\n",
    "BATCH_SIZE = 500000\n",
    "\n",
    "\n",
    "from src.models.pytorch import train_classification, test_classification\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train_classification(train_dataset,\n",
    "                                                 model=model,\n",
    "                                                 criterion=criterion,\n",
    "                                                 optimizer=optimizer,\n",
    "                                                 batch_size=BATCH_SIZE,\n",
    "                                                 device=device\n",
    "                                                )\n",
    "    \n",
    "    valid_loss, valid_acc = test_classification(val_dataset,\n",
    "                                                model=model,\n",
    "                                                criterion=criterion,\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                device=device\n",
    "                                               )\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\t|\\tLoss: {train_loss:.4f}\\t|\\tAcc: {train_acc * 100:.3f}%')\n",
    "    print(f'\\t(valid)\\t|\\tLoss: {valid_loss:.4f}\\t|\\tAcc: {valid_acc * 100:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e425a6c5-c438-465b-834c-3959a7a9012c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.691%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n",
      "Epoch: 1\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n",
      "Epoch: 2\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n",
      "Epoch: 3\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n",
      "Epoch: 4\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "N_EPOCHS = 5\n",
    "BATCH_SIZE = 500000\n",
    "\n",
    "\n",
    "from src.models.pytorch import train_classification, test_classification\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train_classification(train_dataset,\n",
    "                                                 model=model,\n",
    "                                                 criterion=criterion,\n",
    "                                                 optimizer=optimizer,\n",
    "                                                 batch_size=BATCH_SIZE,\n",
    "                                                 device=device\n",
    "                                                )\n",
    "    \n",
    "    valid_loss, valid_acc = test_classification(val_dataset,\n",
    "                                                model=model,\n",
    "                                                criterion=criterion,\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                device=device\n",
    "                                               )\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\t|\\tLoss: {train_loss:.4f}\\t|\\tAcc: {train_acc * 100:.3f}%')\n",
    "    print(f'\\t(valid)\\t|\\tLoss: {valid_loss:.4f}\\t|\\tAcc: {valid_acc * 100:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5dd4698b-a9a8-4361-9668-a0094f12cdec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n",
      "Epoch: 1\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "N_EPOCHS = 2\n",
    "BATCH_SIZE = 500000\n",
    "\n",
    "\n",
    "from src.models.pytorch import train_classification, test_classification\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train_classification(train_dataset,\n",
    "                                                 model=model,\n",
    "                                                 criterion=criterion,\n",
    "                                                 optimizer=optimizer,\n",
    "                                                 batch_size=BATCH_SIZE,\n",
    "                                                 device=device\n",
    "                                                )\n",
    "    \n",
    "    valid_loss, valid_acc = test_classification(val_dataset,\n",
    "                                                model=model,\n",
    "                                                criterion=criterion,\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                device=device\n",
    "                                               )\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\t|\\tLoss: {train_loss:.4f}\\t|\\tAcc: {train_acc * 100:.3f}%')\n",
    "    print(f'\\t(valid)\\t|\\tLoss: {valid_loss:.4f}\\t|\\tAcc: {valid_acc * 100:.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6696a55d-d097-404f-9027-ab2092d774e6",
   "metadata": {},
   "source": [
    "## Experiment 3\n",
    "No difference from Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1485a06f-cd49-4977-907f-d01f99e2f65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate PytorchMultiClass with the correct number of input feature \n",
    "# and save it into a variable called model\n",
    "\n",
    "from src.models.pytorch import PytorchMultiClass\n",
    "model = PytorchMultiClass(X_train.shape[1])\n",
    "\n",
    "\n",
    "# Set model to use the device available\n",
    "from src.models.pytorch import get_device\n",
    "\n",
    "device = get_device()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ae419e-ebee-4da7-b524-d7e8294bbea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "N_EPOCHS = 2\n",
    "BATCH_SIZE = 50000\n",
    "\n",
    "\n",
    "from src.models.pytorch import train_classification, test_classification\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train_classification(train_dataset,\n",
    "                                                 model=model,\n",
    "                                                 criterion=criterion,\n",
    "                                                 optimizer=optimizer,\n",
    "                                                 batch_size=BATCH_SIZE,\n",
    "                                                 device=device\n",
    "                                                )\n",
    "    \n",
    "    valid_loss, valid_acc = test_classification(val_dataset,\n",
    "                                                model=model,\n",
    "                                                criterion=criterion,\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                device=device\n",
    "                                               )\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\t|\\tLoss: {train_loss:.4f}\\t|\\tAcc: {train_acc * 100:.3f}%')\n",
    "    print(f'\\t(valid)\\t|\\tLoss: {valid_loss:.4f}\\t|\\tAcc: {valid_acc * 100:.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535aca64-b473-4266-9d9c-8e0b3170ebd8",
   "metadata": {},
   "source": [
    "## Experiment 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a009fda6-0827-49ee-b807-2901af588531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PytorchMultiClass(\n",
       "  (layer_1): Linear(in_features=6, out_features=50, bias=True)\n",
       "  (layer_out): Linear(in_features=50, out_features=104, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate PytorchMultiClass with the correct number of input feature \n",
    "# and save it into a variable called model\n",
    "\n",
    "from src.models.pytorch import PytorchMultiClass\n",
    "model = PytorchMultiClass(X_train.shape[1])\n",
    "\n",
    "\n",
    "# Set model to use the device available\n",
    "from src.models.pytorch import get_device\n",
    "\n",
    "device = get_device()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7919ae5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 1.097%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n",
      "Epoch: 1\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "N_EPOCHS = 2\n",
    "BATCH_SIZE = 800000\n",
    "\n",
    "\n",
    "from src.models.pytorch import train_classification, test_classification\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train_classification(train_dataset,\n",
    "                                                 model=model,\n",
    "                                                 criterion=criterion,\n",
    "                                                 optimizer=optimizer,\n",
    "                                                 batch_size=BATCH_SIZE,\n",
    "                                                 device=device\n",
    "                                                )\n",
    "    \n",
    "    valid_loss, valid_acc = test_classification(val_dataset,\n",
    "                                                model=model,\n",
    "                                                criterion=criterion,\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                device=device\n",
    "                                               )\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\t|\\tLoss: {train_loss:.4f}\\t|\\tAcc: {train_acc * 100:.3f}%')\n",
    "    print(f'\\t(valid)\\t|\\tLoss: {valid_loss:.4f}\\t|\\tAcc: {valid_acc * 100:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1192ab4b-54c7-405a-bf99-2b610ff97600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n",
      "Epoch: 1\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "N_EPOCHS = 2\n",
    "BATCH_SIZE = 700000\n",
    "\n",
    "\n",
    "from src.models.pytorch import train_classification, test_classification\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train_classification(train_dataset,\n",
    "                                                 model=model,\n",
    "                                                 criterion=criterion,\n",
    "                                                 optimizer=optimizer,\n",
    "                                                 batch_size=BATCH_SIZE,\n",
    "                                                 device=device\n",
    "                                                )\n",
    "    \n",
    "    valid_loss, valid_acc = test_classification(val_dataset,\n",
    "                                                model=model,\n",
    "                                                criterion=criterion,\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                device=device\n",
    "                                               )\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\t|\\tLoss: {train_loss:.4f}\\t|\\tAcc: {train_acc * 100:.3f}%')\n",
    "    print(f'\\t(valid)\\t|\\tLoss: {valid_loss:.4f}\\t|\\tAcc: {valid_acc * 100:.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715f83f9-67f7-4bb5-b388-19dcce08697f",
   "metadata": {},
   "source": [
    "## Experiment 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5488134-b188-4b99-9900-b0a39bdaa289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PytorchMultiClass(\n",
       "  (layer_1): Linear(in_features=6, out_features=50, bias=True)\n",
       "  (layer_out): Linear(in_features=50, out_features=104, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate PytorchMultiClass with the correct number of input feature \n",
    "# and save it into a variable called model\n",
    "\n",
    "from src.models.pytorch import PytorchMultiClass\n",
    "model = PytorchMultiClass(X_train.shape[1])\n",
    "\n",
    "\n",
    "# Set model to use the device available\n",
    "from src.models.pytorch import get_device\n",
    "\n",
    "device = get_device()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f339b24-55b4-443e-8814-41ead68034f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.4970%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.5140%\n",
      "Epoch: 1\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.4821%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.5140%\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "N_EPOCHS = 2\n",
    "BATCH_SIZE = 50000\n",
    "\n",
    "\n",
    "from src.models.pytorch import train_classification, test_classification\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train_classification(train_dataset,\n",
    "                                                 model=model,\n",
    "                                                 criterion=criterion,\n",
    "                                                 optimizer=optimizer,\n",
    "                                                 batch_size=BATCH_SIZE,\n",
    "                                                 device=device\n",
    "                                                )\n",
    "    \n",
    "    valid_loss, valid_acc = test_classification(val_dataset,\n",
    "                                                model=model,\n",
    "                                                criterion=criterion,\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                device=device\n",
    "                                               )\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\t|\\tLoss: {train_loss:.4f}\\t|\\tAcc: {train_acc * 100:.4f}%')\n",
    "    print(f'\\t(valid)\\t|\\tLoss: {valid_loss:.4f}\\t|\\tAcc: {valid_acc * 100:.4f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba542386-45ef-4595-ab47-744c3f13d8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.4821%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.5140%\n",
      "Epoch: 1\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.4821%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.5140%\n",
      "Epoch: 2\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.4821%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.5140%\n",
      "Epoch: 3\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.4821%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.5140%\n",
      "Epoch: 4\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.4821%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.5140%\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "N_EPOCHS = 5\n",
    "BATCH_SIZE = 50000\n",
    "\n",
    "\n",
    "from src.models.pytorch import train_classification, test_classification\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train_classification(train_dataset,\n",
    "                                                 model=model,\n",
    "                                                 criterion=criterion,\n",
    "                                                 optimizer=optimizer,\n",
    "                                                 batch_size=BATCH_SIZE,\n",
    "                                                 device=device\n",
    "                                                )\n",
    "    \n",
    "    valid_loss, valid_acc = test_classification(val_dataset,\n",
    "                                                model=model,\n",
    "                                                criterion=criterion,\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                device=device\n",
    "                                               )\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\t|\\tLoss: {train_loss:.4f}\\t|\\tAcc: {train_acc * 100:.4f}%')\n",
    "    print(f'\\t(valid)\\t|\\tLoss: {valid_loss:.4f}\\t|\\tAcc: {valid_acc * 100:.4f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dde785be-3b54-41e5-9ba3-2fafaebae3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.4821%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.5140%\n",
      "Epoch: 1\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.4821%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.5140%\n",
      "Epoch: 2\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.4821%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.5140%\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "N_EPOCHS = 3\n",
    "BATCH_SIZE = 50000\n",
    "\n",
    "\n",
    "from src.models.pytorch import train_classification, test_classification\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train_classification(train_dataset,\n",
    "                                                 model=model,\n",
    "                                                 criterion=criterion,\n",
    "                                                 optimizer=optimizer,\n",
    "                                                 batch_size=BATCH_SIZE,\n",
    "                                                 device=device\n",
    "                                                )\n",
    "    \n",
    "    valid_loss, valid_acc = test_classification(val_dataset,\n",
    "                                                model=model,\n",
    "                                                criterion=criterion,\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                device=device\n",
    "                                               )\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\t|\\tLoss: {train_loss:.4f}\\t|\\tAcc: {train_acc * 100:.4f}%')\n",
    "    print(f'\\t(valid)\\t|\\tLoss: {valid_loss:.4f}\\t|\\tAcc: {valid_acc * 100:.4f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b903568-c529-4897-96a3-c7c3b6e85293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.4821%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.5140%\n",
      "Epoch: 1\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.4821%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.5140%\n",
      "Epoch: 2\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.4821%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.5140%\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "N_EPOCHS = 3\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "\n",
    "from src.models.pytorch import train_classification, test_classification\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train_classification(train_dataset,\n",
    "                                                 model=model,\n",
    "                                                 criterion=criterion,\n",
    "                                                 optimizer=optimizer,\n",
    "                                                 batch_size=BATCH_SIZE,\n",
    "                                                 device=device\n",
    "                                                )\n",
    "    \n",
    "    valid_loss, valid_acc = test_classification(val_dataset,\n",
    "                                                model=model,\n",
    "                                                criterion=criterion,\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                device=device\n",
    "                                               )\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\t|\\tLoss: {train_loss:.4f}\\t|\\tAcc: {train_acc * 100:.4f}%')\n",
    "    print(f'\\t(valid)\\t|\\tLoss: {valid_loss:.4f}\\t|\\tAcc: {valid_acc * 100:.4f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a39b596-000a-4e00-8762-96c3d3540e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
