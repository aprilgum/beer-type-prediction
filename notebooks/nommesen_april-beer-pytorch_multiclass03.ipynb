{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe619f25-fcdf-4ca1-9887-1fbae68c7b8e",
   "metadata": {},
   "source": [
    "# Beer Prediction Full Model Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c39d6a9-b94e-4dad-9d01-531befbd6339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fe0d94-739e-40ee-8045-7121c4ac1bbf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Transformations (A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf434080-3241-492f-bcf8-d50effd55a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68438470-aada-4081-bf75-4f45ba1a01e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_raw_beer = pd.read_csv('/wd/data/raw/beer_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82d2a141-316d-4c33-8eed-5bbeabc4d817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brewery_name</th>\n",
       "      <th>review_aroma</th>\n",
       "      <th>review_appearance</th>\n",
       "      <th>beer_style</th>\n",
       "      <th>review_palate</th>\n",
       "      <th>review_taste</th>\n",
       "      <th>beer_abv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vecchio Birraio</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Hefeweizen</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vecchio Birraio</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>English Strong Ale</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vecchio Birraio</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Foreign / Export Stout</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vecchio Birraio</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>German Pilsener</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Caldera Brewing Company</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>American Double / Imperial IPA</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              brewery_name  review_aroma  review_appearance  \\\n",
       "0          Vecchio Birraio           2.0                2.5   \n",
       "1          Vecchio Birraio           2.5                3.0   \n",
       "2          Vecchio Birraio           2.5                3.0   \n",
       "3          Vecchio Birraio           3.0                3.5   \n",
       "4  Caldera Brewing Company           4.5                4.0   \n",
       "\n",
       "                       beer_style  review_palate  review_taste  beer_abv  \n",
       "0                      Hefeweizen            1.5           1.5       5.0  \n",
       "1              English Strong Ale            3.0           3.0       6.2  \n",
       "2          Foreign / Export Stout            3.0           3.0       6.5  \n",
       "3                 German Pilsener            2.5           3.0       5.0  \n",
       "4  American Double / Imperial IPA            4.0           4.5       7.7  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned = df_raw_beer.copy()\n",
    "df_cleaned.drop(['brewery_id',\n",
    "                 'review_profilename', \n",
    "                 'review_time',\n",
    "                 'beer_name',\n",
    "                 'beer_beerid',\n",
    "                 'review_overall' # temp exclude\n",
    "                ], axis=1, inplace=True)\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f6f911a-6f12-4651-9d81-b56c9b07196b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a numeric version of the categorical features \n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "cats_dict = dict(enumerate(df_cleaned.brewery_name.unique()))\n",
    "df_cleaned['brewery_name'] = le.fit_transform(df_cleaned['brewery_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5275c648-5915-42f2-ad1a-0cac61f45af6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standardise the numeric features \n",
    "\n",
    "num_cols = ['brewery_name',\n",
    "            'review_aroma',\n",
    "            'review_appearance',\n",
    "            'review_palate',\n",
    "            'review_taste',\n",
    "            'beer_abv']\n",
    "\n",
    "sc = StandardScaler()\n",
    "df_cleaned[num_cols] = sc.fit_transform(df_cleaned[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce636417-fe23-4de0-88be-2d300bc58002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a numeric (integer) version of the target variable \n",
    "\n",
    "cats_dict = dict(enumerate(df_cleaned.beer_style.unique()))\n",
    "le = LabelEncoder()\n",
    "df_cleaned['beer_style'] = le.fit_transform(df_cleaned['beer_style'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6df6df-0408-4640-96ab-3f320dd0bf66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9352757-ad08-4e2c-b247-432216d04f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0bb2ae-8625-4e88-af8c-b482ddff8842",
   "metadata": {},
   "source": [
    "## Split the data (A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd0ba058-7737-4b10-95f0-8f019b664700",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.data.sets import split_sets_random, save_sets\n",
    "\n",
    "# Split the data into training and testing sets with 80-20 ratio\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = split_sets_random(df_cleaned,\n",
    "                                                                   target_col='beer_style',\n",
    "                                                                   test_ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9cbe68d2-171c-448f-b581-10877a383c31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_sets(X_train=X_train,\n",
    "          y_train=y_train,\n",
    "          X_val=X_val,\n",
    "          y_val=y_val,\n",
    "          X_test=X_test,\n",
    "          y_test=y_test,\n",
    "          path='/wd/data/processed/beer_type/'\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ffcfbec-5565-4ab1-bf07-ea0ab4c848f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all sets to PytorchDataset\n",
    "\n",
    "from src.models.pytorch import PytorchDataset\n",
    "\n",
    "train_dataset = PytorchDataset(X=X_train, y=y_train)\n",
    "val_dataset = PytorchDataset(X=X_val, y=y_val)\n",
    "test_dataset = PytorchDataset(X=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f9cc90-13b5-493c-8ada-fc00517de58c",
   "metadata": {},
   "source": [
    "## Baseline Model (A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2a119844-0019-4091-9447-fc41628c2098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NullModel from src.models.null\n",
    "from src.models.null import NullModel\n",
    "\n",
    "baseline_model = NullModel(target_type='classification')\n",
    "y_base = baseline_model.fit_predict(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "55c5cb5b-114b-4e47-930e-964c34913ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Training: 0.0742157299405022\n",
      "F1 Training: 0.01025487603110527\n"
     ]
    }
   ],
   "source": [
    "# Import print_class_perf from src.models.performance\n",
    "from src.models.performance import print_class_perf\n",
    "\n",
    "# Print the classification metrics for this baseline model\n",
    "print_class_perf(y_base, y_train, set_name='Training', average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e3dd45-fd27-4a3e-b155-fb47f0037f16",
   "metadata": {},
   "source": [
    "## Load Stored Data (A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ff1df313-896f-4d86-ac7b-2927fd69a27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.sets import load_sets\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_sets(path='../data/processed/beer_type/'\n",
    "                                                          )\n",
    "                                                           \n",
    "from src.models.pytorch import PytorchDataset\n",
    "\n",
    "train_dataset = PytorchDataset(X=X_train, y=y_train)\n",
    "val_dataset = PytorchDataset(X=X_val, y=y_val)\n",
    "test_dataset = PytorchDataset(X=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1c624d0e-c55d-42e8-b64b-71264d95472d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.08775722, -3.20467771, -1.36609615, -1.09012252, -0.40009933,\n",
       "        -1.09466486],\n",
       "       [-0.05561711, -1.05449924,  0.25703654, -0.35721912, -0.40009933,\n",
       "         0.62759846],\n",
       "       [ 1.11334619, -1.05449924, -0.55452981,  0.37568428, -0.40009933,\n",
       "         0.06786288],\n",
       "       ...,\n",
       "       [ 1.34054826,  0.37895308,  0.25703654,  0.37568428,  0.96607804,\n",
       "         1.14427745],\n",
       "       [ 0.56586437,  0.37895308, -0.55452981, -1.09012252,  0.28298936,\n",
       "        -0.01825029],\n",
       "       [ 0.40630261,  0.37895308,  1.06860288,  0.37568428, -0.40009933,\n",
       "         0.41231554]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train\n",
    "\n",
    "# Note: contains 6 features: \n",
    "            # 'brewery_name',\n",
    "            # 'review_aroma',\n",
    "            # 'review_appearance',\n",
    "            # 'review_palate',\n",
    "            # 'review_taste',\n",
    "            # 'beer_abv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba0141c-9616-409a-9a3a-021ec364ac4d",
   "metadata": {},
   "source": [
    "## Training Experiments (A)\n",
    "\n",
    "Note: contains 6 features: \n",
    "            'brewery_name',\n",
    "            'review_aroma',\n",
    "            'review_appearance',\n",
    "            'review_palate',\n",
    "            'review_taste',\n",
    "            'beer_abv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f15dd0-34bd-4c41-94e6-31a5db5f975c",
   "metadata": {},
   "source": [
    "### Architecture (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f8077194-2b4d-47ce-8ab3-1361e8f637ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PytorchMultiClass(\n",
       "  (layer_1): Linear(in_features=6, out_features=50, bias=True)\n",
       "  (layer_out): Linear(in_features=50, out_features=104, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate PytorchMultiClass with the correct number of input feature \n",
    "# and save it into a variable called model\n",
    "\n",
    "from src.models.pytorch import PytorchMultiClass\n",
    "model = PytorchMultiClass(X_train.shape[1])\n",
    "\n",
    "\n",
    "# Set model to use the device available\n",
    "from src.models.pytorch import get_device\n",
    "\n",
    "device = get_device()\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "146e8bfb-b89b-4fc4-bdff-569075a5b44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PytorchMultiClass(\n",
      "  (layer_1): Linear(in_features=6, out_features=50, bias=True)\n",
      "  (layer_out): Linear(in_features=50, out_features=104, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Print the architecture of model\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939c4fd2-dae4-40cc-a470-8f5faea7fc97",
   "metadata": {},
   "source": [
    "### Train (X)\n",
    "Neural Network Multi-Class Classification with Pytorch\n",
    "\n",
    "**learning rate = 0.1, 0.01, 0.001** \n",
    "\n",
    "**batch size = 500,000**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ad6a6b71-3dd6-4e74-97c8-67143e0584ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.731%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n",
      "Epoch: 1\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n",
      "Epoch: 2\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n",
      "Epoch: 3\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n",
      "Epoch: 4\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "N_EPOCHS = 5\n",
    "BATCH_SIZE = 500000\n",
    "\n",
    "\n",
    "from src.models.pytorch import train_classification, test_classification\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train_classification(train_dataset,\n",
    "                                                 model=model,\n",
    "                                                 criterion=criterion,\n",
    "                                                 optimizer=optimizer,\n",
    "                                                 batch_size=BATCH_SIZE,\n",
    "                                                 device=device\n",
    "                                                )\n",
    "    \n",
    "    valid_loss, valid_acc = test_classification(val_dataset,\n",
    "                                                model=model,\n",
    "                                                criterion=criterion,\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                device=device\n",
    "                                               )\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\t|\\tLoss: {train_loss:.4f}\\t|\\tAcc: {train_acc * 100:.3f}%')\n",
    "    print(f'\\t(valid)\\t|\\tLoss: {valid_loss:.4f}\\t|\\tAcc: {valid_acc * 100:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b1efa5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.691%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n",
      "Epoch: 1\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n",
      "Epoch: 2\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n",
      "Epoch: 3\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n",
      "Epoch: 4\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "N_EPOCHS = 5\n",
    "BATCH_SIZE = 500000\n",
    "\n",
    "\n",
    "from src.models.pytorch import train_classification, test_classification\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train_classification(train_dataset,\n",
    "                                                 model=model,\n",
    "                                                 criterion=criterion,\n",
    "                                                 optimizer=optimizer,\n",
    "                                                 batch_size=BATCH_SIZE,\n",
    "                                                 device=device\n",
    "                                                )\n",
    "    \n",
    "    valid_loss, valid_acc = test_classification(val_dataset,\n",
    "                                                model=model,\n",
    "                                                criterion=criterion,\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                device=device\n",
    "                                               )\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\t|\\tLoss: {train_loss:.4f}\\t|\\tAcc: {train_acc * 100:.3f}%')\n",
    "    print(f'\\t(valid)\\t|\\tLoss: {valid_loss:.4f}\\t|\\tAcc: {valid_acc * 100:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e425a6c5-c438-465b-834c-3959a7a9012c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.691%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n",
      "Epoch: 1\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n",
      "Epoch: 2\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n",
      "Epoch: 3\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n",
      "Epoch: 4\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "N_EPOCHS = 5\n",
    "BATCH_SIZE = 500000\n",
    "\n",
    "\n",
    "from src.models.pytorch import train_classification, test_classification\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train_classification(train_dataset,\n",
    "                                                 model=model,\n",
    "                                                 criterion=criterion,\n",
    "                                                 optimizer=optimizer,\n",
    "                                                 batch_size=BATCH_SIZE,\n",
    "                                                 device=device\n",
    "                                                )\n",
    "    \n",
    "    valid_loss, valid_acc = test_classification(val_dataset,\n",
    "                                                model=model,\n",
    "                                                criterion=criterion,\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                device=device\n",
    "                                               )\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\t|\\tLoss: {train_loss:.4f}\\t|\\tAcc: {train_acc * 100:.3f}%')\n",
    "    print(f'\\t(valid)\\t|\\tLoss: {valid_loss:.4f}\\t|\\tAcc: {valid_acc * 100:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5dd4698b-a9a8-4361-9668-a0094f12cdec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n",
      "Epoch: 1\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "N_EPOCHS = 2\n",
    "BATCH_SIZE = 500000\n",
    "\n",
    "\n",
    "from src.models.pytorch import train_classification, test_classification\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train_classification(train_dataset,\n",
    "                                                 model=model,\n",
    "                                                 criterion=criterion,\n",
    "                                                 optimizer=optimizer,\n",
    "                                                 batch_size=BATCH_SIZE,\n",
    "                                                 device=device\n",
    "                                                )\n",
    "    \n",
    "    valid_loss, valid_acc = test_classification(val_dataset,\n",
    "                                                model=model,\n",
    "                                                criterion=criterion,\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                device=device\n",
    "                                               )\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\t|\\tLoss: {train_loss:.4f}\\t|\\tAcc: {train_acc * 100:.3f}%')\n",
    "    print(f'\\t(valid)\\t|\\tLoss: {valid_loss:.4f}\\t|\\tAcc: {valid_acc * 100:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6ca031-31b0-4e7a-bb22-ff9aefb3de88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "535aca64-b473-4266-9d9c-8e0b3170ebd8",
   "metadata": {},
   "source": [
    "**learning rate = 0.1** \n",
    "\n",
    "**batch size = 800,000**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7919ae5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 1.097%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n",
      "Epoch: 1\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "N_EPOCHS = 2\n",
    "BATCH_SIZE = 800000\n",
    "\n",
    "\n",
    "from src.models.pytorch import train_classification, test_classification\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train_classification(train_dataset,\n",
    "                                                 model=model,\n",
    "                                                 criterion=criterion,\n",
    "                                                 optimizer=optimizer,\n",
    "                                                 batch_size=BATCH_SIZE,\n",
    "                                                 device=device\n",
    "                                                )\n",
    "    \n",
    "    valid_loss, valid_acc = test_classification(val_dataset,\n",
    "                                                model=model,\n",
    "                                                criterion=criterion,\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                device=device\n",
    "                                               )\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\t|\\tLoss: {train_loss:.4f}\\t|\\tAcc: {train_acc * 100:.3f}%')\n",
    "    print(f'\\t(valid)\\t|\\tLoss: {valid_loss:.4f}\\t|\\tAcc: {valid_acc * 100:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c61bb2-ff9c-4633-99fb-e0f43903f330",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05b97abf-d73e-4d79-b849-7e7470b9146b",
   "metadata": {},
   "source": [
    "**learning rate = 0.1** \n",
    "\n",
    "**batch size = 700,000**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1192ab4b-54c7-405a-bf99-2b610ff97600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n",
      "Epoch: 1\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "N_EPOCHS = 2\n",
    "BATCH_SIZE = 700000\n",
    "\n",
    "\n",
    "from src.models.pytorch import train_classification, test_classification\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train_classification(train_dataset,\n",
    "                                                 model=model,\n",
    "                                                 criterion=criterion,\n",
    "                                                 optimizer=optimizer,\n",
    "                                                 batch_size=BATCH_SIZE,\n",
    "                                                 device=device\n",
    "                                                )\n",
    "    \n",
    "    valid_loss, valid_acc = test_classification(val_dataset,\n",
    "                                                model=model,\n",
    "                                                criterion=criterion,\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                device=device\n",
    "                                               )\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\t|\\tLoss: {train_loss:.4f}\\t|\\tAcc: {train_acc * 100:.3f}%')\n",
    "    print(f'\\t(valid)\\t|\\tLoss: {valid_loss:.4f}\\t|\\tAcc: {valid_acc * 100:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604df4c8-597c-408d-861e-321936e8ee9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0b4eacd-e974-44b1-bf8c-d4fdc110b3be",
   "metadata": {},
   "source": [
    "**learning rate = 0.1, 0.01, 0.001** \n",
    "\n",
    "**batch size = 50,000**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f339b24-55b4-443e-8814-41ead68034f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.4970%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.5140%\n",
      "Epoch: 1\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.4821%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.5140%\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "N_EPOCHS = 2\n",
    "BATCH_SIZE = 50000\n",
    "\n",
    "\n",
    "from src.models.pytorch import train_classification, test_classification\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train_classification(train_dataset,\n",
    "                                                 model=model,\n",
    "                                                 criterion=criterion,\n",
    "                                                 optimizer=optimizer,\n",
    "                                                 batch_size=BATCH_SIZE,\n",
    "                                                 device=device\n",
    "                                                )\n",
    "    \n",
    "    valid_loss, valid_acc = test_classification(val_dataset,\n",
    "                                                model=model,\n",
    "                                                criterion=criterion,\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                device=device\n",
    "                                               )\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\t|\\tLoss: {train_loss:.4f}\\t|\\tAcc: {train_acc * 100:.4f}%')\n",
    "    print(f'\\t(valid)\\t|\\tLoss: {valid_loss:.4f}\\t|\\tAcc: {valid_acc * 100:.4f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba542386-45ef-4595-ab47-744c3f13d8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.4821%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.5140%\n",
      "Epoch: 1\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.4821%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.5140%\n",
      "Epoch: 2\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.4821%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.5140%\n",
      "Epoch: 3\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.4821%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.5140%\n",
      "Epoch: 4\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.4821%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.5140%\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "N_EPOCHS = 5\n",
    "BATCH_SIZE = 50000\n",
    "\n",
    "\n",
    "from src.models.pytorch import train_classification, test_classification\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train_classification(train_dataset,\n",
    "                                                 model=model,\n",
    "                                                 criterion=criterion,\n",
    "                                                 optimizer=optimizer,\n",
    "                                                 batch_size=BATCH_SIZE,\n",
    "                                                 device=device\n",
    "                                                )\n",
    "    \n",
    "    valid_loss, valid_acc = test_classification(val_dataset,\n",
    "                                                model=model,\n",
    "                                                criterion=criterion,\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                device=device\n",
    "                                               )\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\t|\\tLoss: {train_loss:.4f}\\t|\\tAcc: {train_acc * 100:.4f}%')\n",
    "    print(f'\\t(valid)\\t|\\tLoss: {valid_loss:.4f}\\t|\\tAcc: {valid_acc * 100:.4f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dde785be-3b54-41e5-9ba3-2fafaebae3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.4821%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.5140%\n",
      "Epoch: 1\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.4821%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.5140%\n",
      "Epoch: 2\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.4821%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.5140%\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "N_EPOCHS = 3\n",
    "BATCH_SIZE = 50000\n",
    "\n",
    "\n",
    "from src.models.pytorch import train_classification, test_classification\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train_classification(train_dataset,\n",
    "                                                 model=model,\n",
    "                                                 criterion=criterion,\n",
    "                                                 optimizer=optimizer,\n",
    "                                                 batch_size=BATCH_SIZE,\n",
    "                                                 device=device\n",
    "                                                )\n",
    "    \n",
    "    valid_loss, valid_acc = test_classification(val_dataset,\n",
    "                                                model=model,\n",
    "                                                criterion=criterion,\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                device=device\n",
    "                                               )\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\t|\\tLoss: {train_loss:.4f}\\t|\\tAcc: {train_acc * 100:.4f}%')\n",
    "    print(f'\\t(valid)\\t|\\tLoss: {valid_loss:.4f}\\t|\\tAcc: {valid_acc * 100:.4f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b1cbad-ec1b-43c0-8a5b-665220c3b159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fe26309-d5a2-4af6-8d5f-ccdabb8b6a9f",
   "metadata": {},
   "source": [
    "**learning rate = 0.1** \n",
    "\n",
    "**batch size = 50**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b903568-c529-4897-96a3-c7c3b6e85293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.4821%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.5140%\n",
      "Epoch: 1\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.4821%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.5140%\n",
      "Epoch: 2\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.4821%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.5140%\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "N_EPOCHS = 3\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "\n",
    "from src.models.pytorch import train_classification, test_classification\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train_classification(train_dataset,\n",
    "                                                 model=model,\n",
    "                                                 criterion=criterion,\n",
    "                                                 optimizer=optimizer,\n",
    "                                                 batch_size=BATCH_SIZE,\n",
    "                                                 device=device\n",
    "                                                )\n",
    "    \n",
    "    valid_loss, valid_acc = test_classification(val_dataset,\n",
    "                                                model=model,\n",
    "                                                criterion=criterion,\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                device=device\n",
    "                                               )\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\t|\\tLoss: {train_loss:.4f}\\t|\\tAcc: {train_acc * 100:.4f}%')\n",
    "    print(f'\\t(valid)\\t|\\tLoss: {valid_loss:.4f}\\t|\\tAcc: {valid_acc * 100:.4f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf418821-9385-47ad-843a-efe58c861b20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083a580c-312f-40e3-97d6-83339ed02223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0108406a-c07c-4970-8690-288fdeeff379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33c19df2-fb45-43f8-8ac2-337ab9d8e533",
   "metadata": {},
   "source": [
    "## Training Experiments (B)\n",
    "\n",
    "Note: contains 6 features: \n",
    "            'brewery_name',\n",
    "            'review_aroma',\n",
    "            'review_appearance',\n",
    "            'review_palate',\n",
    "            'review_taste',\n",
    "            'beer_abv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02ab958a-2971-4fb0-9526-e0da2c559112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cced68a7-e96c-43a5-922e-4cfdad673bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.sets import load_sets\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_sets(path='../data/processed/beer_type/'\n",
    "                                                          )\n",
    "                                            \n",
    "from src.models.pytorch import PytorchDataset\n",
    "\n",
    "train_dataset = PytorchDataset(X=X_train, y=y_train)\n",
    "val_dataset = PytorchDataset(X=X_val, y=y_val)\n",
    "test_dataset = PytorchDataset(X=X_test, y=y_test)                                                           \n",
    "                                                           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8a30c5-6fd5-4c25-ab50-a6a90db103ad",
   "metadata": {},
   "source": [
    "### Architecture (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47b74b15-2697-4749-b0ae-8c7d60b043ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PytorchMultiClass(\n",
       "  (layer_1): Linear(in_features=6, out_features=500, bias=True)\n",
       "  (layer_out): Linear(in_features=500, out_features=104, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate PytorchMultiClass with the correct number of input feature \n",
    "# and save it into a variable called model\n",
    "\n",
    "from src.models.pytorch import PytorchMultiClass\n",
    "model = PytorchMultiClass(X_train.shape[1])\n",
    "\n",
    "\n",
    "# Set model to use the device available\n",
    "from src.models.pytorch import get_device\n",
    "\n",
    "device = get_device()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148f5bc2-4f61-426c-8fa3-f9cee6cc4bba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "680c46a2-adea-455e-9ad6-c04227362750",
   "metadata": {},
   "source": [
    "**learning rate = 0.1** \n",
    "\n",
    "**batch size = 500000**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10835b88-a570-4b82-aa45-20eba4ab3728",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "N_EPOCHS = 5\n",
    "BATCH_SIZE = 500000\n",
    "\n",
    "\n",
    "from src.models.pytorch import train_classification, test_classification\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train_classification(train_dataset,\n",
    "                                                 model=model,\n",
    "                                                 criterion=criterion,\n",
    "                                                 optimizer=optimizer,\n",
    "                                                 batch_size=BATCH_SIZE,\n",
    "                                                 device=device\n",
    "                                                )\n",
    "    \n",
    "    valid_loss, valid_acc = test_classification(val_dataset,\n",
    "                                                model=model,\n",
    "                                                criterion=criterion,\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                device=device\n",
    "                                               )\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\t|\\tLoss: {train_loss:.4f}\\t|\\tAcc: {train_acc * 100:.3f}%')\n",
    "    print(f'\\t(valid)\\t|\\tLoss: {valid_loss:.4f}\\t|\\tAcc: {valid_acc * 100:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0595ae-aa34-45d3-b616-2a08249eed80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27c0b00e-e5ab-4ed1-831d-97886c588776",
   "metadata": {},
   "source": [
    "## Training Experiments (C)\n",
    "\n",
    "Note: contains **5 features**: \n",
    "            'review_aroma',\n",
    "            'review_appearance',\n",
    "            'review_palate',\n",
    "            'review_taste',\n",
    "            'beer_abv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed55420-0106-4ad5-813a-064b4ee6171f",
   "metadata": {},
   "source": [
    "#### New Data Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b005e5a-4467-417e-ba38-9d88bb282b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "135a42f6-585e-457c-b846-7a397c0308ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_beer = pd.read_csv('/wd/data/raw/beer_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0650860-da45-4a85-8249-392e5c2ac6a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_aroma</th>\n",
       "      <th>review_appearance</th>\n",
       "      <th>beer_style</th>\n",
       "      <th>review_palate</th>\n",
       "      <th>review_taste</th>\n",
       "      <th>beer_abv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Hefeweizen</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>English Strong Ale</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Foreign / Export Stout</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>German Pilsener</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>American Double / Imperial IPA</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_aroma  review_appearance                      beer_style  \\\n",
       "0           2.0                2.5                      Hefeweizen   \n",
       "1           2.5                3.0              English Strong Ale   \n",
       "2           2.5                3.0          Foreign / Export Stout   \n",
       "3           3.0                3.5                 German Pilsener   \n",
       "4           4.5                4.0  American Double / Imperial IPA   \n",
       "\n",
       "   review_palate  review_taste  beer_abv  \n",
       "0            1.5           1.5       5.0  \n",
       "1            3.0           3.0       6.2  \n",
       "2            3.0           3.0       6.5  \n",
       "3            2.5           3.0       5.0  \n",
       "4            4.0           4.5       7.7  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned = df_raw_beer.copy()\n",
    "df_cleaned.drop(['brewery_id',\n",
    "                 'review_profilename', \n",
    "                 'review_time',\n",
    "                 'beer_name',\n",
    "                 'beer_beerid',\n",
    "                 'review_overall', # temp exclude\n",
    "                 'brewery_name' # not include in the model\n",
    "                ], axis=1, inplace=True)\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2614f3b1-af40-4734-9474-7fcdb22816ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_aroma</th>\n",
       "      <th>review_appearance</th>\n",
       "      <th>beer_style</th>\n",
       "      <th>review_palate</th>\n",
       "      <th>review_taste</th>\n",
       "      <th>beer_abv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.487952</td>\n",
       "      <td>-2.177663</td>\n",
       "      <td>Hefeweizen</td>\n",
       "      <td>-3.288833</td>\n",
       "      <td>-3.132454</td>\n",
       "      <td>-0.879382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.771225</td>\n",
       "      <td>-1.366096</td>\n",
       "      <td>English Strong Ale</td>\n",
       "      <td>-1.090123</td>\n",
       "      <td>-1.083188</td>\n",
       "      <td>-0.362703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.771225</td>\n",
       "      <td>-1.366096</td>\n",
       "      <td>Foreign / Export Stout</td>\n",
       "      <td>-1.090123</td>\n",
       "      <td>-1.083188</td>\n",
       "      <td>-0.233533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.054499</td>\n",
       "      <td>-0.554530</td>\n",
       "      <td>German Pilsener</td>\n",
       "      <td>-1.823026</td>\n",
       "      <td>-1.083188</td>\n",
       "      <td>-0.879382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.095679</td>\n",
       "      <td>0.257037</td>\n",
       "      <td>American Double / Imperial IPA</td>\n",
       "      <td>0.375684</td>\n",
       "      <td>0.966078</td>\n",
       "      <td>0.283146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_aroma  review_appearance                      beer_style  \\\n",
       "0     -2.487952          -2.177663                      Hefeweizen   \n",
       "1     -1.771225          -1.366096              English Strong Ale   \n",
       "2     -1.771225          -1.366096          Foreign / Export Stout   \n",
       "3     -1.054499          -0.554530                 German Pilsener   \n",
       "4      1.095679           0.257037  American Double / Imperial IPA   \n",
       "\n",
       "   review_palate  review_taste  beer_abv  \n",
       "0      -3.288833     -3.132454 -0.879382  \n",
       "1      -1.090123     -1.083188 -0.362703  \n",
       "2      -1.090123     -1.083188 -0.233533  \n",
       "3      -1.823026     -1.083188 -0.879382  \n",
       "4       0.375684      0.966078  0.283146  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardise the numeric features \n",
    "\n",
    "\n",
    "num_cols = ['review_aroma',\n",
    "            'review_appearance',\n",
    "            'review_palate',\n",
    "            'review_taste',\n",
    "            'beer_abv']\n",
    "sc = StandardScaler()\n",
    "df_cleaned[num_cols] = sc.fit_transform(df_cleaned[num_cols])\n",
    "\n",
    "df_cleaned.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "427700b5-ff54-4af3-ad4f-442cbf91e2e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_aroma</th>\n",
       "      <th>review_appearance</th>\n",
       "      <th>beer_style</th>\n",
       "      <th>review_palate</th>\n",
       "      <th>review_taste</th>\n",
       "      <th>beer_abv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.487952</td>\n",
       "      <td>-2.177663</td>\n",
       "      <td>65</td>\n",
       "      <td>-3.288833</td>\n",
       "      <td>-3.132454</td>\n",
       "      <td>-0.879382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.771225</td>\n",
       "      <td>-1.366096</td>\n",
       "      <td>51</td>\n",
       "      <td>-1.090123</td>\n",
       "      <td>-1.083188</td>\n",
       "      <td>-0.362703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.771225</td>\n",
       "      <td>-1.366096</td>\n",
       "      <td>59</td>\n",
       "      <td>-1.090123</td>\n",
       "      <td>-1.083188</td>\n",
       "      <td>-0.233533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.054499</td>\n",
       "      <td>-0.554530</td>\n",
       "      <td>61</td>\n",
       "      <td>-1.823026</td>\n",
       "      <td>-1.083188</td>\n",
       "      <td>-0.879382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.095679</td>\n",
       "      <td>0.257037</td>\n",
       "      <td>9</td>\n",
       "      <td>0.375684</td>\n",
       "      <td>0.966078</td>\n",
       "      <td>0.283146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586609</th>\n",
       "      <td>0.378953</td>\n",
       "      <td>-0.554530</td>\n",
       "      <td>85</td>\n",
       "      <td>0.375684</td>\n",
       "      <td>0.282989</td>\n",
       "      <td>-0.793269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586610</th>\n",
       "      <td>1.812405</td>\n",
       "      <td>-2.177663</td>\n",
       "      <td>85</td>\n",
       "      <td>-2.555929</td>\n",
       "      <td>0.282989</td>\n",
       "      <td>-0.793269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586611</th>\n",
       "      <td>-0.337773</td>\n",
       "      <td>-1.366096</td>\n",
       "      <td>85</td>\n",
       "      <td>-0.357219</td>\n",
       "      <td>0.282989</td>\n",
       "      <td>-0.793269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586612</th>\n",
       "      <td>1.095679</td>\n",
       "      <td>1.068603</td>\n",
       "      <td>85</td>\n",
       "      <td>1.108588</td>\n",
       "      <td>0.966078</td>\n",
       "      <td>-0.793269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586613</th>\n",
       "      <td>1.095679</td>\n",
       "      <td>1.068603</td>\n",
       "      <td>85</td>\n",
       "      <td>1.108588</td>\n",
       "      <td>0.966078</td>\n",
       "      <td>-0.793269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1586614 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         review_aroma  review_appearance  beer_style  review_palate  \\\n",
       "0           -2.487952          -2.177663          65      -3.288833   \n",
       "1           -1.771225          -1.366096          51      -1.090123   \n",
       "2           -1.771225          -1.366096          59      -1.090123   \n",
       "3           -1.054499          -0.554530          61      -1.823026   \n",
       "4            1.095679           0.257037           9       0.375684   \n",
       "...               ...                ...         ...            ...   \n",
       "1586609      0.378953          -0.554530          85       0.375684   \n",
       "1586610      1.812405          -2.177663          85      -2.555929   \n",
       "1586611     -0.337773          -1.366096          85      -0.357219   \n",
       "1586612      1.095679           1.068603          85       1.108588   \n",
       "1586613      1.095679           1.068603          85       1.108588   \n",
       "\n",
       "         review_taste  beer_abv  \n",
       "0           -3.132454 -0.879382  \n",
       "1           -1.083188 -0.362703  \n",
       "2           -1.083188 -0.233533  \n",
       "3           -1.083188 -0.879382  \n",
       "4            0.966078  0.283146  \n",
       "...               ...       ...  \n",
       "1586609      0.282989 -0.793269  \n",
       "1586610      0.282989 -0.793269  \n",
       "1586611      0.282989 -0.793269  \n",
       "1586612      0.966078 -0.793269  \n",
       "1586613      0.966078 -0.793269  \n",
       "\n",
       "[1586614 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a numeric (integer) version of the target variable \n",
    "\n",
    "cats_dict = dict(enumerate(df_cleaned.beer_style.unique()))\n",
    "le = LabelEncoder()\n",
    "df_cleaned['beer_style'] = le.fit_transform(df_cleaned['beer_style'])\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317fadab-69b9-4ac1-814e-a5c04c70d90c",
   "metadata": {},
   "source": [
    "#### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96f30ec2-9e56-46f1-8144-45bfbe3e0438",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.sets import split_sets_random, save_sets\n",
    "\n",
    "# Split the data into training and testing sets with 80-20 ratio\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = split_sets_random(df_cleaned,\n",
    "                                                                   target_col='beer_style',\n",
    "                                                                   test_ratio=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b7e1da5-b80d-4579-9805-b71911a339a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_sets(X_train=X_train,\n",
    "          y_train=y_train,\n",
    "          X_val=X_val,\n",
    "          y_val=y_val,\n",
    "          X_test=X_test,\n",
    "          y_test=y_test,\n",
    "          path='/wd/data/processed/beer_type/'\n",
    "         )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "115dfd47-74ae-4008-a7dc-479773d71227",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.sets import load_sets\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_sets(path='../data/processed/beer_type/'\n",
    "                                                          )\n",
    "                                                           \n",
    "from src.models.pytorch import PytorchDataset\n",
    "\n",
    "train_dataset = PytorchDataset(X=X_train, y=y_train)\n",
    "val_dataset = PytorchDataset(X=X_val, y=y_val)\n",
    "test_dataset = PytorchDataset(X=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "493201af-a4c0-409c-ad60-9b27f6038e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.20467771, -1.36609615, -1.09012252, -0.40009933, -1.09466486],\n",
       "       [-1.05449924,  0.25703654, -0.35721912, -0.40009933,  0.62759846],\n",
       "       [-1.05449924, -0.55452981,  0.37568428, -0.40009933,  0.06786288],\n",
       "       ...,\n",
       "       [ 0.37895308,  0.25703654,  0.37568428,  0.96607804,  1.14427745],\n",
       "       [ 0.37895308, -0.55452981, -1.09012252,  0.28298936, -0.01825029],\n",
       "       [ 0.37895308,  1.06860288,  0.37568428, -0.40009933,  0.41231554]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06bcd72-2a1e-4b84-8799-3bfac049dcec",
   "metadata": {},
   "source": [
    "#### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d62949d8-36e1-414f-a2c1-835760fdba0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/wd/src/models/null.py:43: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  self.pred_value = mode(y)[0][0]\n"
     ]
    }
   ],
   "source": [
    "# Import NullModel from src.models.null\n",
    "from src.models.null import NullModel\n",
    "\n",
    "baseline_model = NullModel(target_type='classification')\n",
    "y_base = baseline_model.fit_predict(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b774529a-405b-4c06-8e42-21965de2c43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Training: 0.0742157299405022\n",
      "F1 Training: 0.01025487603110527\n"
     ]
    }
   ],
   "source": [
    "# Import print_class_perf from src.models.performance\n",
    "from src.models.performance import print_class_perf\n",
    "\n",
    "# Print the classification metrics for this baseline model\n",
    "print_class_perf(y_base, y_train, set_name='Training', average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce45b0c-c3b5-4535-a9e0-bd533bf4f492",
   "metadata": {},
   "source": [
    "### Architecture (Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99a4b130-6498-469a-a05a-f43b790fbb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "91646224-5c4e-40fc-9109-08a42e40ba23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PytorchMultiClass(\n",
       "  (layer_1): Linear(in_features=5, out_features=500, bias=True)\n",
       "  (layer_out): Linear(in_features=500, out_features=104, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate PytorchMultiClass with the correct number of input feature \n",
    "# and save it into a variable called model\n",
    "\n",
    "from src.models.pytorch import PytorchMultiClass\n",
    "model = PytorchMultiClass(X_train.shape[1])\n",
    "\n",
    "\n",
    "# Set model to use the device available\n",
    "from src.models.pytorch import get_device\n",
    "\n",
    "device = get_device()\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "373c5a2a-42e7-4636-a933-7be1bc1c7a4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.834%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n",
      "Epoch: 1\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n",
      "Epoch: 2\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n",
      "Epoch: 3\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n",
      "Epoch: 4\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "N_EPOCHS = 5\n",
    "BATCH_SIZE = 500000\n",
    "\n",
    "\n",
    "from src.models.pytorch import train_classification, test_classificatiocn\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train_classification(train_dataset,\n",
    "                                                model=model,\n",
    "                                                 criterion=criterion,\n",
    "                                                 optimizer=optimizer,\n",
    "                                                 batch_size=BATCH_SIZE,\n",
    "                                                 device=device\n",
    "                                                )\n",
    "    \n",
    "    valid_loss, valid_acc = test_classification(val_dataset,\n",
    "                                                model=model,\n",
    "                                                criterion=criterion,\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                device=device\n",
    "                                               )\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\t|\\tLoss: {train_loss:.4f}\\t|\\tAcc: {train_acc * 100:.3f}%')\n",
    "    print(f'\\t(valid)\\t|\\tLoss: {valid_loss:.4f}\\t|\\tAcc: {valid_acc * 100:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02045b7a-622a-4130-aba7-0af09c3a3f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c709a10-2b3d-4fab-8967-1a804370ff9a",
   "metadata": {},
   "source": [
    "### Architecture (W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39171d85-6633-4027-8db8-a263df904384",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba356d41-ad88-4c15-a8c1-f3e9d07e38fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.sets import load_sets\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_sets(path='../data/processed/beer_type/'\n",
    "                                                          )\n",
    "                                                           \n",
    "from src.models.pytorch import PytorchDataset\n",
    "\n",
    "train_dataset = PytorchDataset(X=X_train, y=y_train)\n",
    "val_dataset = PytorchDataset(X=X_val, y=y_val)\n",
    "test_dataset = PytorchDataset(X=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abfa71b3-3066-41cd-bdb4-03a2fbbf7a03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PytorchMultiClass(\n",
       "  (layer_1): Linear(in_features=5, out_features=50, bias=True)\n",
       "  (layer_out): Linear(in_features=50, out_features=104, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate PytorchMultiClass with the correct number of input feature \n",
    "# and save it into a variable called model\n",
    "\n",
    "from src.models.pytorch import PytorchMultiClass\n",
    "model = PytorchMultiClass(X_train.shape[1])\n",
    "\n",
    "\n",
    "# Set model to use the device available\n",
    "from src.models.pytorch import get_device\n",
    "\n",
    "device = get_device()\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fe71c25-2228-4f75-82c1-15f45c8a9633",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 1.009%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n",
      "Epoch: 1\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n",
      "Epoch: 2\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n",
      "Epoch: 3\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n",
      "Epoch: 4\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "N_EPOCHS = 5\n",
    "BATCH_SIZE = 500000\n",
    "\n",
    "\n",
    "from src.models.pytorch import train_classification, test_classification\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train_classification(train_dataset,\n",
    "                                                model=model,\n",
    "                                                 criterion=criterion,\n",
    "                                                 optimizer=optimizer,\n",
    "                                                 batch_size=BATCH_SIZE,\n",
    "                                                 device=device\n",
    "                                                )\n",
    "    \n",
    "    valid_loss, valid_acc = test_classification(val_dataset,\n",
    "                                                model=model,\n",
    "                                                criterion=criterion,\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                device=device\n",
    "                                               )\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\t|\\tLoss: {train_loss:.4f}\\t|\\tAcc: {train_acc * 100:.3f}%')\n",
    "    print(f'\\t(valid)\\t|\\tLoss: {valid_loss:.4f}\\t|\\tAcc: {valid_acc * 100:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4a4c334-9e00-43df-99b8-27dc00991253",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n",
      "Epoch: 1\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "N_EPOCHS = 2\n",
    "BATCH_SIZE = 100000\n",
    "\n",
    "\n",
    "from src.models.pytorch import train_classification, test_classification\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train_classification(train_dataset,\n",
    "                                                model=model,\n",
    "                                                 criterion=criterion,\n",
    "                                                 optimizer=optimizer,\n",
    "                                                 batch_size=BATCH_SIZE,\n",
    "                                                 device=device\n",
    "                                                )\n",
    "    \n",
    "    valid_loss, valid_acc = test_classification(val_dataset,\n",
    "                                                model=model,\n",
    "                                                criterion=criterion,\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                device=device\n",
    "                                               )\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\t|\\tLoss: {train_loss:.4f}\\t|\\tAcc: {train_acc * 100:.3f}%')\n",
    "    print(f'\\t(valid)\\t|\\tLoss: {valid_loss:.4f}\\t|\\tAcc: {valid_acc * 100:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c21bfa8-da81-4010-9ffd-10cdf53612e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n",
      "Epoch: 1\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "N_EPOCHS = 2\n",
    "BATCH_SIZE = 50000\n",
    "\n",
    "\n",
    "from src.models.pytorch import train_classification, test_classification\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train_classification(train_dataset,\n",
    "                                                model=model,\n",
    "                                                 criterion=criterion,\n",
    "                                                 optimizer=optimizer,\n",
    "                                                 batch_size=BATCH_SIZE,\n",
    "                                                 device=device\n",
    "                                                )\n",
    "    \n",
    "    valid_loss, valid_acc = test_classification(val_dataset,\n",
    "                                                model=model,\n",
    "                                                criterion=criterion,\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                device=device\n",
    "                                               )\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\t|\\tLoss: {train_loss:.4f}\\t|\\tAcc: {train_acc * 100:.3f}%')\n",
    "    print(f'\\t(valid)\\t|\\tLoss: {valid_loss:.4f}\\t|\\tAcc: {valid_acc * 100:.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92aa3c2f-5e21-41b5-a1ea-e057b423e3d2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd02f2f5-2a4f-427f-a802-d00b2bf5f214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52a075e4-3956-4d4f-8318-da4ed26122a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PytorchMultiClass(\n",
       "  (layer_1): Linear(in_features=5, out_features=500, bias=True)\n",
       "  (layer_out): Linear(in_features=500, out_features=104, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate PytorchMultiClass with the correct number of input feature \n",
    "# and save it into a variable called model\n",
    "\n",
    "from src.models.pytorch import PytorchMultiClass\n",
    "model = PytorchMultiClass(X_train.shape[1])\n",
    "\n",
    "\n",
    "# Set model to use the device available\n",
    "from src.models.pytorch import get_device\n",
    "\n",
    "device = get_device()\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92b9c995-83f6-417e-82be-1f051ec466ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.503%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n",
      "Epoch: 1\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "N_EPOCHS = 2\n",
    "BATCH_SIZE = 50000\n",
    "\n",
    "\n",
    "from src.models.pytorch import train_classification, test_classification\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train_classification(train_dataset,\n",
    "                                                model=model,\n",
    "                                                 criterion=criterion,\n",
    "                                                 optimizer=optimizer,\n",
    "                                                 batch_size=BATCH_SIZE,\n",
    "                                                 device=device\n",
    "                                                )\n",
    "    \n",
    "    valid_loss, valid_acc = test_classification(val_dataset,\n",
    "                                                model=model,\n",
    "                                                criterion=criterion,\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                device=device\n",
    "                                               )\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\t|\\tLoss: {train_loss:.4f}\\t|\\tAcc: {train_acc * 100:.3f}%')\n",
    "    print(f'\\t(valid)\\t|\\tLoss: {valid_loss:.4f}\\t|\\tAcc: {valid_acc * 100:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9997c19-e13f-452b-9f92-a94afad60e24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "N_EPOCHS = 2\n",
    "BATCH_SIZE = 500000\n",
    "\n",
    "\n",
    "from src.models.pytorch import train_classification, test_classification\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train_classification(train_dataset,\n",
    "                                                model=model,\n",
    "                                                 criterion=criterion,\n",
    "                                                 optimizer=optimizer,\n",
    "                                                 batch_size=BATCH_SIZE,\n",
    "                                                 device=device\n",
    "                                                )\n",
    "    \n",
    "    valid_loss, valid_acc = test_classification(val_dataset,\n",
    "                                                model=model,\n",
    "                                                criterion=criterion,\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                device=device\n",
    "                                               )\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\t|\\tLoss: {train_loss:.4f}\\t|\\tAcc: {train_acc * 100:.3f}%')\n",
    "    print(f'\\t(valid)\\t|\\tLoss: {valid_loss:.4f}\\t|\\tAcc: {valid_acc * 100:.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3894a6f8-8f4b-4f11-9b85-2d41ee84f6f3",
   "metadata": {},
   "source": [
    "### Architecture (V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15d0c12c-7ffc-4ee3-8c9a-43e34333b4ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45a44ec0-0968-4773-81a4-c36250d5881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.sets import load_sets\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_sets(path='../data/processed/beer_type/'\n",
    "                                                          )\n",
    "                                                           \n",
    "from src.models.pytorch import PytorchDataset\n",
    "\n",
    "train_dataset = PytorchDataset(X=X_train, y=y_train)\n",
    "val_dataset = PytorchDataset(X=X_val, y=y_val)\n",
    "test_dataset = PytorchDataset(X=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88ab91f5-6ab1-43d8-8a97-a13d7cf57bd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PytorchMultiClass(\n",
       "  (layer_1): Linear(in_features=5, out_features=5, bias=True)\n",
       "  (layer_out): Linear(in_features=5, out_features=104, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate PytorchMultiClass with the correct number of input feature \n",
    "# and save it into a variable called model\n",
    "\n",
    "from src.models.pytorch import PytorchMultiClass\n",
    "model = PytorchMultiClass(X_train.shape[1])\n",
    "\n",
    "\n",
    "# Set model to use the device available\n",
    "from src.models.pytorch import get_device\n",
    "\n",
    "device = get_device()\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f2b53b1-c50d-46d2-b70d-bb252ef2b8b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.780%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n",
      "Epoch: 1\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n",
      "Epoch: 2\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n",
      "Epoch: 3\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n",
      "Epoch: 4\n",
      "\t(train)\t|\tLoss: nan\t|\tAcc: 0.482%\n",
      "\t(valid)\t|\tLoss: nan\t|\tAcc: 0.514%\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "N_EPOCHS = 5\n",
    "BATCH_SIZE = 500000\n",
    "\n",
    "\n",
    "from src.models.pytorch import train_classification, test_classification\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train_classification(train_dataset,\n",
    "                                                model=model,\n",
    "                                                 criterion=criterion,\n",
    "                                                 optimizer=optimizer,\n",
    "                                                 batch_size=BATCH_SIZE,\n",
    "                                                 device=device\n",
    "                                                )\n",
    "    \n",
    "    valid_loss, valid_acc = test_classification(val_dataset,\n",
    "                                                model=model,\n",
    "                                                criterion=criterion,\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                device=device\n",
    "                                               )\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\t|\\tLoss: {train_loss:.4f}\\t|\\tAcc: {train_acc * 100:.3f}%')\n",
    "    print(f'\\t(valid)\\t|\\tLoss: {valid_loss:.4f}\\t|\\tAcc: {valid_acc * 100:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3d43ad-ec8f-41e1-ae48-6c4c6795dba9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
